\chapter{Mitigation Framework}
\label{chap:mitigation}

In the event of a comet remnant impact, the impacting material is likely to often pass perihelion (and thus approach impact with the Earth) on the order of a few years after discovery. In the most extreme examples, highly eccentric LPC nuclei may only become visible once within the orbit of Jupiter - leaving only a few month's time to react. 

Therefore, strategies that mitigate against Earth-bound cometary material are of a different nature to the more popular proposed planetary defence efforts that focus primarily on asteroids. Such strategies focus on mitigating against high energy objects with a short-warning time. Recent discussions of direct comet mitigation in literature range from the use of large phased-array lasers illuminating LPC nuclei from afar \citep{2016PASP..128d5001Z}, to a nuclear explosive device affixed to an interceptor craft that waits in stand-by in an orbit around Earth \citep{7500925, HUSSEIN2016488}. %A nuclear detonation is one of the few plausible mitigation strategies that could sufficiently deflect a comet away from Earth, and even then may only be feasible if sent to meet the comet almost immediately upon discovery. 

However in this paper we advocate a more detection-based approach, developing a Random Forest classification model to detect hazardous evolving cometary material scattered in the Solar System from our current catalogues of small bodies detected from Earth. Such a framework may permit greater understanding of the nature of hazardous cometary material presently being scattered through the Solar System, and therefore inform us on how best to develop a response.

We develop a mitigation framework that acts purely on the dynamical qualities of a comet's orbit, and neglects features such as a comet's size and other physical attributes. In developing a detection method to look for evidence of dangerous cometary material, regardless of size, composition etc - we hope to look for cometary remnants that could themselves be an direct threat to Earth, or that could be genetically associated with an as of yet unobserved threatening parent comet nuclei or host of fragmented material.

\section{Random Forest Model}

As discovered in \S~\ref{chap:results}, cometary material in the Solar System is continuously scattered on through the Solar System, along vibrant dynamical pathways dominated by resonances, diffusion, and chaos. While N-body integrations help us understand the various dynamical pathways that a comet may take, they are inherently computationally intensive processes that make them unsatisfactory for examining the long-term evolution of a specific object and how it may pose a risk to our planet.

We instead select a large sample of orbital features from our N-body simulation, and use this to train a predictive model in order classify objects with similar orbital characteristics as hazardous. Hazardous orbits from the simulation are used in a learning algorithm alongside non-hazardous orbits with more asteroidal dynamical characteristics - sourced from the JPL small body database.

We selected a large number of datapoints from our simulation data at various points in time. In particular we selected simulated comets that i) entered the Earth's loss cone only once ii) most of their dynamical lifetimes beyond the orbit of Jupiter iii) were initially bound to the Solar System. This selection was chosen in order to prioritise cometary material that could represent the dominant impact hazard, ie. those that rapidly and chaotically evolve through the Solar System, and arrive in the NEO environment with short warning times. From this selection of datapoints we used an 8:2 split for training and validation purposes respectively.

The Random Forest Classification Model is made up of an ensemble of many classification decision trees, which themselves individually separate the feature space of a training data set into smaller and smaller partitions. In an attempt to limit a decision tree's ability to `overfit' to the data it's been trained on, we aggregate a number of decision trees into one final structure known as a random forest. 

We implement our random forest using the \textsc{CART} decision tree algorithm \citep{breiman2017classification} from the \texttt{Python} library \texttt{scikit-learn} \citep{cournapeau2015sci}. During the training process, at the point of a particular feature partition, the algorithm maximises the efficiency of a tree such that the Gini impurity $I_G$ of the two resulting feature partitions is minimised. The Gini impurity can be calculated by summing the probability $p_f$ of an item with label $f$  being chosen multiplied by the probability of a mistake in categorising that item.  It is given by,

\vspace{-1ex}
\begin{equation}
   I_G =  \sum_{k = 0}^k p_f(1-p_f)~,
\end{equation}

where $K$ is the number of classes. For our model we use $K=2$, where the two classes denote hazardous cometary material and non-hazardous material. 

We trained our random forest algorithm using five orbital elements as features. These were $(a,e,i,\Omega,\omega)$ - semi-major axis, eccentricity, inclination, longitude of ascending node, and argument of perihelion respectively. These features completely describe the shape and orientation of a comet's orbit relative to the Sun, neglecting the comet's particular position in time. These features therefore encode all the necessary information (for example velocity, value of $T_J$) that permit a classification on whether the object is hazardous or not.

100 individual trees were trained with a maximum depth of 10 levels in order to reduce overfitting. Once all the individual decision trees had been calculated, with each tree operating on a random subset of the training data, the result was then averaged into a random forest - much more accurate than an individual decision tree. With a trained random forest, orbital elements were then be propagated through the structure and a predicted classification was then output.

\section{Results}

Our model performed well against our validation data, with 77\% of results predicting a hazardous orbit being correct, with 85\% of the hazardous comets classified successfully. 

%Unlike other predictive models which have more of a black box nature, each trained decision tree in our random forest could be individually studied and interpreted by humans. By examining the total reduction of $I_G$ due to a particular feature across all our decision trees, we were able to calculate the relative importance of each feature used for classification. We found that $a$ and $e$ were the most important determining features of an object's orbit as to whether it is hazardous or not.

When the random forest was applied to all known small bodies as catalogued by the JPL small body database, around 192 ($\sim0.1\%$) of the objects were classed as having similar orbital evolutionary characteristics as the dangerous comets in our simulation. This group of objects were made up 70\% LPCs, 19\% SPCs, 11\% eccentric asteroids and minor planets - all at various stages in their dynamical evolution. Notable classifications included; the NEO 4341 Poseidon - associated with the Taurid Complex of meteor showers \citep{2001A&A...373..329B}, 944 Hidalgo - one of the first centaurs to be discovered, and 109P/Swift-Tuttle - described by \cite{verschuur1997impact} as the `the single most dangerous object known to humanity'.


%Notable classifications include objects on eccentric orbits that are already classified as NEOs and are therefore relevant to the human epoch. These included the NEOs 2003 EH1, 2004 UL, and 2004 TG$_{10}$. The notable 109P/Swiftâ€“Tuttle comet was classified as hazardous.

%https://www.repository.cam.ac.uk/bitstream/handle/1810/246615/MNRAS-2015-Shannon-2059-64.pdf?sequence=1 read S5